from backend.chains import run_web_scraping

import os
import streamlit as st

from dotenv import find_dotenv, load_dotenv
from streamlit import session_state as sst

# from langchain_anthropic import ChatAnthropic
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_core.messages import (
    AIMessage,
    HumanMessage,
)
from langchain_openai import ChatOpenAI

load_dotenv(find_dotenv())

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "jinair-test"


st.set_page_config(layout="wide")
MODEL_NAME = "gpt-3.5-turbo-0125"
GREETING = "ì•ˆë…•í•˜ì„¸ìš”. ğŸ¤– Jaidì…ë‹ˆë‹¤! í•­ê³µí¸ ì¡°íšŒë‚˜ ìì£¼ë¬»ëŠ”ì§ˆë¬¸ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ìš”ğŸ˜€"


# @st.cache_resource
def load_chains(model_name, temp=0.0):
    # anthropic = ChatAnthropic(
    #     model_name="claude-3-5-sonnet-20240620", temperature=temp, verbose=True
    # )
    sst.openai_4o = ChatOpenAI(model_name="gpt-4o", temperature=temp, verbose=True)
    print("ğŸš’ Chains have been newly created.")


if "messages" not in sst:
    sst.messages = []
    sst.steps = []
    load_chains(model_name=MODEL_NAME)

# ì¶œë ¥ë˜ëŠ” ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •

st.title("JinAir Jaid í¬ë¡¤ë§ ê¸°ë°˜ QnA ğŸ¤–")

with st.chat_message("ai"):
    st.markdown(GREETING)

# ëŒ€í™” ë‚´ì—­ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
for i, message in enumerate(sst.messages):
    role = "human" if isinstance(message, HumanMessage) else "ai"
    with st.chat_message(role):
        st.markdown(message.content)


if prompt := st.chat_input(""):
    sst.steps.append(None)
    with st.chat_message("human"):
        st.markdown(prompt)

    with st.chat_message("assistant"):

        answer = run_web_scraping(
            prompt,
            sst.openai_4o,
            root_url="https://help.jinair.com/hc/ko/categories/4408759363353-%EC%9E%90%EC%A3%BC-%EB%AC%BB%EB%8A%94-%EC%A7%88%EB%AC%B8-FAQ",
        )

        sst.reply_placeholder = st.empty()
        sst.reply_placeholder.markdown(answer)
        final_answer = answer

    sst.messages.append(HumanMessage(content=prompt))
    sst.messages.append(AIMessage(content=final_answer))
